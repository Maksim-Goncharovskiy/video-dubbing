{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Дообучение XTTS-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:31:08.445933Z",
     "iopub.status.busy": "2025-07-17T10:31:08.445676Z",
     "iopub.status.idle": "2025-07-17T10:33:38.936964Z",
     "shell.execute_reply": "2025-07-17T10:33:38.935798Z",
     "shell.execute_reply.started": "2025-07-17T10:31:08.445912Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cu124 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-07-17T10:35:25.133346Z",
     "iopub.status.busy": "2025-07-17T10:35:25.133111Z",
     "iopub.status.idle": "2025-07-17T10:35:28.266107Z",
     "shell.execute_reply": "2025-07-17T10:35:28.265225Z",
     "shell.execute_reply.started": "2025-07-17T10:35:25.133322Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install transformers==4.37.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-07-17T10:33:51.582992Z",
     "iopub.status.busy": "2025-07-17T10:33:51.582713Z",
     "iopub.status.idle": "2025-07-17T10:35:25.131526Z",
     "shell.execute_reply": "2025-07-17T10:35:25.130810Z",
     "shell.execute_reply.started": "2025-07-17T10:33:51.582965Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/coqui-ai/TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:35:33.768435Z",
     "iopub.status.busy": "2025-07-17T10:35:33.768148Z",
     "iopub.status.idle": "2025-07-17T10:35:35.747343Z",
     "shell.execute_reply": "2025-07-17T10:35:35.746684Z",
     "shell.execute_reply.started": "2025-07-17T10:35:33.768407Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip show torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:48:41.410566Z",
     "iopub.status.busy": "2025-07-17T10:48:41.410235Z",
     "iopub.status.idle": "2025-07-17T10:48:41.415106Z",
     "shell.execute_reply": "2025-07-17T10:48:41.414248Z",
     "shell.execute_reply.started": "2025-07-17T10:48:41.410540Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from trainer import Trainer, TrainerArgs\n",
    "\n",
    "from TTS.config.shared_configs import BaseDatasetConfig\n",
    "from TTS.tts.datasets import load_tts_samples\n",
    "from TTS.tts.layers.xtts.trainer.gpt_trainer import GPTArgs, GPTTrainer, GPTTrainerConfig, XttsAudioConfig\n",
    "from TTS.utils.manage import ModelManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:48:45.058270Z",
     "iopub.status.busy": "2025-07-17T10:48:45.057563Z",
     "iopub.status.idle": "2025-07-17T10:48:45.062816Z",
     "shell.execute_reply": "2025-07-17T10:48:45.062041Z",
     "shell.execute_reply.started": "2025-07-17T10:48:45.058247Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "OUT_PATH = '/kaggle/working/run/'\n",
    "os.makedirs(OUT_PATH, exist_ok=True)\n",
    "\n",
    "CHECKPOINTS_OUT_PATH = os.path.join(OUT_PATH, \"XTTS_v2.0_original_model_files/\")\n",
    "os.makedirs(CHECKPOINTS_OUT_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-07-17T10:36:21.400946Z",
     "iopub.status.busy": "2025-07-17T10:36:21.400627Z",
     "iopub.status.idle": "2025-07-17T10:36:43.709428Z",
     "shell.execute_reply": "2025-07-17T10:36:43.708731Z",
     "shell.execute_reply.started": "2025-07-17T10:36:21.400913Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Downloading DVAE files!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0.00/1.07k [00:00<?, ?iB/s]\n",
      "100%|██████████| 1.07k/1.07k [00:00<00:00, 1.28kiB/s]\n",
      "\n",
      "  5%|▍         | 9.73M/211M [00:00<00:02, 97.3MiB/s]\u001b[A\n",
      " 10%|█         | 21.1M/211M [00:00<00:01, 107MiB/s] \u001b[A\n",
      " 15%|█▌        | 32.6M/211M [00:00<00:01, 110MiB/s]\u001b[A\n",
      " 21%|██        | 43.6M/211M [00:00<00:01, 106MiB/s]\u001b[A\n",
      " 26%|██▋       | 55.5M/211M [00:00<00:01, 110MiB/s]\u001b[A\n",
      " 32%|███▏      | 67.1M/211M [00:00<00:01, 112MiB/s]\u001b[A\n",
      " 38%|███▊      | 79.0M/211M [00:00<00:01, 114MiB/s]\u001b[A\n",
      " 43%|████▎     | 90.9M/211M [00:00<00:01, 116MiB/s]\u001b[A\n",
      " 49%|████▉     | 103M/211M [00:00<00:00, 117MiB/s] \u001b[A\n",
      " 54%|█████▍    | 115M/211M [00:01<00:00, 117MiB/s]\u001b[A\n",
      " 60%|██████    | 126M/211M [00:01<00:00, 115MiB/s]\u001b[A\n",
      " 66%|██████▌   | 138M/211M [00:01<00:00, 110MiB/s]\u001b[A\n",
      " 71%|███████   | 149M/211M [00:01<00:00, 105MiB/s]\u001b[A\n",
      " 76%|███████▌  | 160M/211M [00:01<00:00, 107MiB/s]\u001b[A\n",
      " 81%|████████  | 171M/211M [00:01<00:00, 106MiB/s]\u001b[A\n",
      " 86%|████████▌ | 181M/211M [00:01<00:00, 105MiB/s]\u001b[A\n",
      " 92%|█████████▏| 193M/211M [00:01<00:00, 109MiB/s]\u001b[A\n",
      " 97%|█████████▋| 205M/211M [00:01<00:00, 111MiB/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Downloading XTTS v2.0 files!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211M/211M [00:02<00:00, 88.0MiB/s]\n",
      "\n",
      "361kiB [00:00, 415kiB/s]87G [00:00<?, ?iB/s]\u001b[A\n",
      "\n",
      "  1%|          | 9.57M/1.87G [00:00<00:19, 95.7MiB/s]\u001b[A\n",
      "  1%|          | 21.0M/1.87G [00:00<00:17, 107MiB/s] \u001b[A\n",
      "  2%|▏         | 31.7M/1.87G [00:00<00:18, 100MiB/s]\u001b[A\n",
      "  2%|▏         | 41.7M/1.87G [00:00<00:18, 96.9MiB/s]\u001b[A\n",
      "  3%|▎         | 53.4M/1.87G [00:00<00:17, 104MiB/s] \u001b[A\n",
      "  3%|▎         | 65.1M/1.87G [00:00<00:16, 108MiB/s]\u001b[A\n",
      "  4%|▍         | 77.0M/1.87G [00:00<00:16, 112MiB/s]\u001b[A\n",
      "  5%|▍         | 88.2M/1.87G [00:00<00:16, 107MiB/s]\u001b[A\n",
      "  5%|▌         | 100M/1.87G [00:00<00:16, 110MiB/s] \u001b[A\n",
      "  6%|▌         | 111M/1.87G [00:01<00:16, 106MiB/s]\u001b[A\n",
      "  7%|▋         | 123M/1.87G [00:01<00:15, 109MiB/s]\u001b[A\n",
      "  7%|▋         | 135M/1.87G [00:01<00:15, 112MiB/s]\u001b[A\n",
      "  8%|▊         | 146M/1.87G [00:01<00:15, 113MiB/s]\u001b[A\n",
      "  8%|▊         | 158M/1.87G [00:01<00:14, 114MiB/s]\u001b[A\n",
      "  9%|▉         | 170M/1.87G [00:01<00:14, 115MiB/s]\u001b[A\n",
      " 10%|▉         | 182M/1.87G [00:01<00:14, 116MiB/s]\u001b[A\n",
      " 10%|█         | 193M/1.87G [00:01<00:14, 117MiB/s]\u001b[A\n",
      " 11%|█         | 205M/1.87G [00:01<00:15, 110MiB/s]\u001b[A\n",
      " 12%|█▏        | 216M/1.87G [00:01<00:15, 110MiB/s]\u001b[A\n",
      " 12%|█▏        | 227M/1.87G [00:02<00:14, 110MiB/s]\u001b[A\n",
      " 13%|█▎        | 238M/1.87G [00:02<00:14, 109MiB/s]\u001b[A\n",
      " 13%|█▎        | 249M/1.87G [00:02<00:14, 109MiB/s]\u001b[A\n",
      " 14%|█▍        | 261M/1.87G [00:02<00:14, 111MiB/s]\u001b[A\n",
      " 15%|█▍        | 273M/1.87G [00:02<00:14, 113MiB/s]\u001b[A\n",
      " 15%|█▌        | 284M/1.87G [00:02<00:13, 115MiB/s]\u001b[A\n",
      " 16%|█▌        | 296M/1.87G [00:02<00:13, 115MiB/s]\u001b[A\n",
      " 16%|█▋        | 308M/1.87G [00:02<00:13, 116MiB/s]\u001b[A\n",
      " 17%|█▋        | 320M/1.87G [00:02<00:13, 117MiB/s]\u001b[A\n",
      " 18%|█▊        | 332M/1.87G [00:02<00:13, 118MiB/s]\u001b[A\n",
      " 18%|█▊        | 343M/1.87G [00:03<00:13, 115MiB/s]\u001b[A\n",
      " 19%|█▉        | 355M/1.87G [00:03<00:13, 113MiB/s]\u001b[A\n",
      " 20%|█▉        | 367M/1.87G [00:03<00:13, 114MiB/s]\u001b[A\n",
      " 20%|██        | 378M/1.87G [00:03<00:12, 115MiB/s]\u001b[A\n",
      " 21%|██        | 390M/1.87G [00:03<00:13, 111MiB/s]\u001b[A\n",
      " 21%|██▏       | 401M/1.87G [00:03<00:13, 110MiB/s]\u001b[A\n",
      " 22%|██▏       | 412M/1.87G [00:03<00:13, 110MiB/s]\u001b[A\n",
      " 23%|██▎       | 423M/1.87G [00:03<00:13, 105MiB/s]\u001b[A\n",
      " 23%|██▎       | 433M/1.87G [00:03<00:14, 100MiB/s]\u001b[A\n",
      " 24%|██▍       | 444M/1.87G [00:04<00:13, 103MiB/s]\u001b[A\n",
      " 24%|██▍       | 455M/1.87G [00:04<00:13, 104MiB/s]\u001b[A\n",
      " 25%|██▍       | 466M/1.87G [00:04<00:13, 106MiB/s]\u001b[A\n",
      " 26%|██▌       | 477M/1.87G [00:04<00:13, 105MiB/s]\u001b[A\n",
      " 26%|██▌       | 488M/1.87G [00:04<00:13, 106MiB/s]\u001b[A\n",
      " 27%|██▋       | 499M/1.87G [00:04<00:12, 108MiB/s]\u001b[A\n",
      " 27%|██▋       | 509M/1.87G [00:04<00:13, 101MiB/s]\u001b[A\n",
      " 28%|██▊       | 521M/1.87G [00:04<00:12, 105MiB/s]\u001b[A\n",
      " 28%|██▊       | 532M/1.87G [00:04<00:12, 106MiB/s]\u001b[A\n",
      " 29%|██▉       | 544M/1.87G [00:04<00:12, 109MiB/s]\u001b[A\n",
      " 30%|██▉       | 555M/1.87G [00:05<00:11, 111MiB/s]\u001b[A\n",
      " 30%|███       | 567M/1.87G [00:05<00:11, 113MiB/s]\u001b[A\n",
      " 31%|███       | 579M/1.87G [00:05<00:11, 114MiB/s]\u001b[A\n",
      " 32%|███▏      | 590M/1.87G [00:05<00:11, 115MiB/s]\u001b[A\n",
      " 32%|███▏      | 602M/1.87G [00:05<00:11, 109MiB/s]\u001b[A\n",
      " 33%|███▎      | 613M/1.87G [00:05<00:11, 108MiB/s]\u001b[A\n",
      " 33%|███▎      | 624M/1.87G [00:05<00:11, 105MiB/s]\u001b[A\n",
      " 34%|███▍      | 635M/1.87G [00:05<00:11, 106MiB/s]\u001b[A\n",
      " 35%|███▍      | 645M/1.87G [00:05<00:11, 107MiB/s]\u001b[A\n",
      " 35%|███▌      | 656M/1.87G [00:06<00:11, 107MiB/s]\u001b[A\n",
      " 36%|███▌      | 668M/1.87G [00:06<00:10, 110MiB/s]\u001b[A\n",
      " 36%|███▋      | 679M/1.87G [00:06<00:10, 108MiB/s]\u001b[A\n",
      " 37%|███▋      | 691M/1.87G [00:06<00:10, 111MiB/s]\u001b[A\n",
      " 38%|███▊      | 702M/1.87G [00:06<00:10, 110MiB/s]\u001b[A\n",
      " 38%|███▊      | 713M/1.87G [00:06<00:10, 110MiB/s]\u001b[A\n",
      " 39%|███▉      | 725M/1.87G [00:06<00:10, 112MiB/s]\u001b[A\n",
      " 39%|███▉      | 736M/1.87G [00:06<00:09, 114MiB/s]\u001b[A\n",
      " 40%|████      | 748M/1.87G [00:06<00:09, 115MiB/s]\u001b[A\n",
      " 41%|████      | 760M/1.87G [00:06<00:09, 116MiB/s]\u001b[A\n",
      " 41%|████▏     | 772M/1.87G [00:07<00:09, 117MiB/s]\u001b[A\n",
      " 42%|████▏     | 784M/1.87G [00:07<00:09, 117MiB/s]\u001b[A\n",
      " 43%|████▎     | 796M/1.87G [00:07<00:09, 118MiB/s]\u001b[A\n",
      " 43%|████▎     | 807M/1.87G [00:07<00:09, 118MiB/s]\u001b[A\n",
      " 44%|████▍     | 819M/1.87G [00:07<00:08, 117MiB/s]\u001b[A\n",
      " 44%|████▍     | 831M/1.87G [00:07<00:08, 117MiB/s]\u001b[A\n",
      " 45%|████▌     | 843M/1.87G [00:07<00:08, 118MiB/s]\u001b[A\n",
      " 46%|████▌     | 855M/1.87G [00:07<00:08, 118MiB/s]\u001b[A\n",
      " 46%|████▋     | 867M/1.87G [00:07<00:08, 115MiB/s]\u001b[A\n",
      " 47%|████▋     | 878M/1.87G [00:07<00:08, 113MiB/s]\u001b[A\n",
      " 48%|████▊     | 890M/1.87G [00:08<00:09, 108MiB/s]\u001b[A\n",
      " 48%|████▊     | 901M/1.87G [00:08<00:08, 108MiB/s]\u001b[A\n",
      " 49%|████▉     | 912M/1.87G [00:08<00:08, 109MiB/s]\u001b[A\n",
      " 49%|████▉     | 922M/1.87G [00:08<00:08, 108MiB/s]\u001b[A\n",
      " 50%|████▉     | 933M/1.87G [00:08<00:08, 106MiB/s]\u001b[A\n",
      " 51%|█████     | 944M/1.87G [00:08<00:08, 105MiB/s]\u001b[A\n",
      " 51%|█████     | 955M/1.87G [00:08<00:08, 107MiB/s]\u001b[A\n",
      " 52%|█████▏    | 966M/1.87G [00:08<00:08, 109MiB/s]\u001b[A\n",
      " 52%|█████▏    | 978M/1.87G [00:08<00:08, 110MiB/s]\u001b[A\n",
      " 53%|█████▎    | 989M/1.87G [00:08<00:07, 112MiB/s]\u001b[A\n",
      " 54%|█████▎    | 1.00G/1.87G [00:09<00:07, 114MiB/s]\u001b[A\n",
      " 54%|█████▍    | 1.01G/1.87G [00:09<00:07, 108MiB/s]\u001b[A\n",
      " 55%|█████▍    | 1.02G/1.87G [00:09<00:08, 105MiB/s]\u001b[A\n",
      " 55%|█████▌    | 1.04G/1.87G [00:09<00:07, 108MiB/s]\u001b[A\n",
      " 56%|█████▌    | 1.05G/1.87G [00:09<00:07, 105MiB/s]\u001b[A\n",
      " 57%|█████▋    | 1.06G/1.87G [00:09<00:07, 108MiB/s]\u001b[A\n",
      " 57%|█████▋    | 1.07G/1.87G [00:09<00:07, 111MiB/s]\u001b[A\n",
      " 58%|█████▊    | 1.08G/1.87G [00:09<00:06, 113MiB/s]\u001b[A\n",
      " 58%|█████▊    | 1.09G/1.87G [00:09<00:07, 109MiB/s]\u001b[A\n",
      " 59%|█████▉    | 1.10G/1.87G [00:10<00:07, 105MiB/s]\u001b[A\n",
      " 60%|█████▉    | 1.11G/1.87G [00:10<00:07, 102MiB/s]\u001b[A\n",
      " 60%|██████    | 1.12G/1.87G [00:10<00:07, 101MiB/s]\u001b[A\n",
      " 61%|██████    | 1.14G/1.87G [00:10<00:06, 105MiB/s]\u001b[A\n",
      " 61%|██████▏   | 1.15G/1.87G [00:10<00:06, 109MiB/s]\u001b[A\n",
      " 62%|██████▏   | 1.16G/1.87G [00:10<00:06, 104MiB/s]\u001b[A\n",
      " 63%|██████▎   | 1.17G/1.87G [00:10<00:06, 102MiB/s]\u001b[A\n",
      " 63%|██████▎   | 1.18G/1.87G [00:10<00:06, 106MiB/s]\u001b[A\n",
      " 64%|██████▍   | 1.19G/1.87G [00:10<00:06, 105MiB/s]\u001b[A\n",
      " 64%|██████▍   | 1.20G/1.87G [00:10<00:06, 105MiB/s]\u001b[A\n",
      " 65%|██████▍   | 1.21G/1.87G [00:11<00:06, 105MiB/s]\u001b[A\n",
      " 65%|██████▌   | 1.22G/1.87G [00:11<00:06, 103MiB/s]\u001b[A\n",
      " 66%|██████▌   | 1.23G/1.87G [00:11<00:06, 101MiB/s]\u001b[A\n",
      " 67%|██████▋   | 1.24G/1.87G [00:11<00:06, 99.0MiB/s]\u001b[A\n",
      " 67%|██████▋   | 1.25G/1.87G [00:11<00:06, 101MiB/s] \u001b[A\n",
      " 68%|██████▊   | 1.27G/1.87G [00:11<00:05, 105MiB/s]\u001b[A\n",
      " 68%|██████▊   | 1.28G/1.87G [00:11<00:05, 108MiB/s]\u001b[A\n",
      " 69%|██████▉   | 1.29G/1.87G [00:11<00:05, 108MiB/s]\u001b[A\n",
      " 70%|██████▉   | 1.30G/1.87G [00:11<00:05, 110MiB/s]\u001b[A\n",
      " 70%|███████   | 1.31G/1.87G [00:11<00:04, 112MiB/s]\u001b[A\n",
      " 71%|███████   | 1.32G/1.87G [00:12<00:04, 111MiB/s]\u001b[A\n",
      " 71%|███████▏  | 1.33G/1.87G [00:12<00:04, 110MiB/s]\u001b[A\n",
      " 72%|███████▏  | 1.34G/1.87G [00:12<00:04, 109MiB/s]\u001b[A\n",
      " 73%|███████▎  | 1.36G/1.87G [00:12<00:04, 110MiB/s]\u001b[A\n",
      " 73%|███████▎  | 1.37G/1.87G [00:12<00:04, 105MiB/s]\u001b[A\n",
      " 74%|███████▍  | 1.38G/1.87G [00:12<00:04, 108MiB/s]\u001b[A\n",
      " 74%|███████▍  | 1.39G/1.87G [00:12<00:04, 108MiB/s]\u001b[A\n",
      " 75%|███████▍  | 1.40G/1.87G [00:12<00:04, 104MiB/s]\u001b[A\n",
      " 76%|███████▌  | 1.41G/1.87G [00:12<00:04, 105MiB/s]\u001b[A\n",
      " 76%|███████▌  | 1.42G/1.87G [00:13<00:04, 103MiB/s]\u001b[A\n",
      " 77%|███████▋  | 1.43G/1.87G [00:13<00:04, 101MiB/s]\u001b[A\n",
      " 77%|███████▋  | 1.44G/1.87G [00:13<00:04, 102MiB/s]\u001b[A\n",
      " 78%|███████▊  | 1.45G/1.87G [00:13<00:03, 104MiB/s]\u001b[A\n",
      " 78%|███████▊  | 1.46G/1.87G [00:13<00:03, 107MiB/s]\u001b[A\n",
      " 79%|███████▉  | 1.48G/1.87G [00:13<00:03, 109MiB/s]\u001b[A\n",
      " 80%|███████▉  | 1.49G/1.87G [00:13<00:03, 111MiB/s]\u001b[A\n",
      " 80%|████████  | 1.50G/1.87G [00:13<00:03, 113MiB/s]\u001b[A\n",
      " 81%|████████  | 1.51G/1.87G [00:13<00:03, 111MiB/s]\u001b[A\n",
      " 82%|████████▏ | 1.52G/1.87G [00:13<00:03, 113MiB/s]\u001b[A\n",
      " 82%|████████▏ | 1.53G/1.87G [00:14<00:03, 108MiB/s]\u001b[A\n",
      " 83%|████████▎ | 1.54G/1.87G [00:14<00:03, 108MiB/s]\u001b[A\n",
      " 83%|████████▎ | 1.56G/1.87G [00:14<00:02, 111MiB/s]\u001b[A\n",
      " 84%|████████▍ | 1.57G/1.87G [00:14<00:02, 112MiB/s]\u001b[A\n",
      " 85%|████████▍ | 1.58G/1.87G [00:14<00:02, 111MiB/s]\u001b[A\n",
      " 85%|████████▌ | 1.59G/1.87G [00:14<00:02, 107MiB/s]\u001b[A\n",
      " 86%|████████▌ | 1.60G/1.87G [00:14<00:02, 94.6MiB/s]\u001b[A\n",
      " 86%|████████▌ | 1.61G/1.87G [00:14<00:02, 90.5MiB/s]\u001b[A\n",
      " 87%|████████▋ | 1.62G/1.87G [00:14<00:02, 84.3MiB/s]\u001b[A\n",
      " 87%|████████▋ | 1.63G/1.87G [00:15<00:02, 86.2MiB/s]\u001b[A\n",
      " 88%|████████▊ | 1.64G/1.87G [00:15<00:02, 85.4MiB/s]\u001b[A\n",
      " 88%|████████▊ | 1.65G/1.87G [00:15<00:02, 85.1MiB/s]\u001b[A\n",
      " 89%|████████▊ | 1.66G/1.87G [00:15<00:02, 87.1MiB/s]\u001b[A\n",
      " 89%|████████▉ | 1.67G/1.87G [00:15<00:02, 91.3MiB/s]\u001b[A\n",
      " 90%|████████▉ | 1.68G/1.87G [00:15<00:02, 85.1MiB/s]\u001b[A\n",
      " 90%|█████████ | 1.68G/1.87G [00:15<00:02, 80.7MiB/s]\u001b[A\n",
      " 91%|█████████ | 1.69G/1.87G [00:15<00:02, 83.0MiB/s]\u001b[A\n",
      " 91%|█████████ | 1.70G/1.87G [00:15<00:02, 82.0MiB/s]\u001b[A\n",
      " 92%|█████████▏| 1.71G/1.87G [00:16<00:02, 76.0MiB/s]\u001b[A\n",
      " 92%|█████████▏| 1.72G/1.87G [00:16<00:01, 80.2MiB/s]\u001b[A\n",
      " 93%|█████████▎| 1.73G/1.87G [00:16<00:01, 84.6MiB/s]\u001b[A\n",
      " 93%|█████████▎| 1.74G/1.87G [00:16<00:01, 87.0MiB/s]\u001b[A\n",
      " 94%|█████████▎| 1.75G/1.87G [00:16<00:01, 89.4MiB/s]\u001b[A\n",
      " 94%|█████████▍| 1.76G/1.87G [00:16<00:01, 96.8MiB/s]\u001b[A\n",
      " 95%|█████████▍| 1.77G/1.87G [00:16<00:01, 98.3MiB/s]\u001b[A\n",
      " 95%|█████████▌| 1.78G/1.87G [00:16<00:00, 104MiB/s] \u001b[A\n",
      " 96%|█████████▌| 1.79G/1.87G [00:16<00:00, 108MiB/s]\u001b[A\n",
      " 97%|█████████▋| 1.80G/1.87G [00:16<00:00, 110MiB/s]\u001b[A\n",
      " 97%|█████████▋| 1.82G/1.87G [00:17<00:00, 112MiB/s]\u001b[A\n",
      " 98%|█████████▊| 1.83G/1.87G [00:17<00:00, 114MiB/s]\u001b[A\n",
      " 98%|█████████▊| 1.84G/1.87G [00:17<00:00, 114MiB/s]\u001b[A\n",
      " 99%|█████████▉| 1.85G/1.87G [00:17<00:00, 107MiB/s]\u001b[A\n",
      "100%|█████████▉| 1.86G/1.87G [00:17<00:00, 102MiB/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "# DVAE files\n",
    "DVAE_CHECKPOINT_LINK = \"https://coqui.gateway.scarf.sh/hf-coqui/XTTS-v2/main/dvae.pth\"\n",
    "MEL_NORM_LINK = \"https://coqui.gateway.scarf.sh/hf-coqui/XTTS-v2/main/mel_stats.pth\"\n",
    "\n",
    "# Set the path to the downloaded files\n",
    "DVAE_CHECKPOINT = os.path.join(CHECKPOINTS_OUT_PATH, os.path.basename(DVAE_CHECKPOINT_LINK))\n",
    "MEL_NORM_FILE = os.path.join(CHECKPOINTS_OUT_PATH, os.path.basename(MEL_NORM_LINK))\n",
    "\n",
    "# download DVAE files if needed\n",
    "if not os.path.isfile(DVAE_CHECKPOINT) or not os.path.isfile(MEL_NORM_FILE):\n",
    "    print(\" > Downloading DVAE files!\")\n",
    "    ModelManager._download_model_files([MEL_NORM_LINK, DVAE_CHECKPOINT_LINK], CHECKPOINTS_OUT_PATH, progress_bar=True)\n",
    "\n",
    "# Download XTTS v2.0 checkpoint if needed\n",
    "TOKENIZER_FILE_LINK = \"https://coqui.gateway.scarf.sh/hf-coqui/XTTS-v2/main/vocab.json\"\n",
    "XTTS_CHECKPOINT_LINK = \"https://coqui.gateway.scarf.sh/hf-coqui/XTTS-v2/main/model.pth\"\n",
    "\n",
    "# XTTS transfer learning parameters: You we need to provide the paths of XTTS model checkpoint that you want to do the fine tuning.\n",
    "TOKENIZER_FILE = os.path.join(CHECKPOINTS_OUT_PATH, os.path.basename(TOKENIZER_FILE_LINK))  # vocab.json file\n",
    "XTTS_CHECKPOINT = os.path.join(CHECKPOINTS_OUT_PATH, os.path.basename(XTTS_CHECKPOINT_LINK))  # model.pth file\n",
    "\n",
    "# download XTTS v2.0 files if needed\n",
    "if not os.path.isfile(TOKENIZER_FILE) or not os.path.isfile(XTTS_CHECKPOINT):\n",
    "    print(\" > Downloading XTTS v2.0 files!\")\n",
    "    ModelManager._download_model_files(\n",
    "        [TOKENIZER_FILE_LINK, XTTS_CHECKPOINT_LINK], CHECKPOINTS_OUT_PATH, progress_bar=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:36:58.913933Z",
     "iopub.status.busy": "2025-07-17T10:36:58.913259Z",
     "iopub.status.idle": "2025-07-17T10:36:58.917220Z",
     "shell.execute_reply": "2025-07-17T10:36:58.916550Z",
     "shell.execute_reply.started": "2025-07-17T10:36:58.913907Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1.87G/1.87G [00:35<00:00, 102MiB/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "training_dir = \"/kaggle/input/the-lj-speech-dataset/LJSpeech-1.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:48:48.407927Z",
     "iopub.status.busy": "2025-07-17T10:48:48.407636Z",
     "iopub.status.idle": "2025-07-17T10:48:48.412228Z",
     "shell.execute_reply": "2025-07-17T10:48:48.411387Z",
     "shell.execute_reply.started": "2025-07-17T10:48:48.407905Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "OPTIMIZER_WD_ONLY_ON_WEIGHTS = True  # for multi-gpu training please make it False\n",
    "START_WITH_EVAL = True  # if True it will star with evaluation\n",
    "BATCH_SIZE = 2  # set here the batch size\n",
    "GRAD_ACUMM_STEPS = 64  # set here the grad accumulation steps\n",
    "LANGUAGE = \"en\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Конфигурация датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:48:49.382596Z",
     "iopub.status.busy": "2025-07-17T10:48:49.382276Z",
     "iopub.status.idle": "2025-07-17T10:48:49.387028Z",
     "shell.execute_reply": "2025-07-17T10:48:49.386163Z",
     "shell.execute_reply.started": "2025-07-17T10:48:49.382573Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "config_dataset = BaseDatasetConfig(\n",
    "    formatter=\"ljspeech\",\n",
    "    dataset_name=\"ljspeech\",\n",
    "    path=\"/kaggle/input/the-lj-speech-dataset/LJSpeech-1.1\",\n",
    "    meta_file_train=\"/kaggle/input/the-lj-speech-dataset/LJSpeech-1.1/metadata.csv\",\n",
    "    language=\"en\",\n",
    ")\n",
    "\n",
    "DATASETS_CONFIG_LIST = [config_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:48:51.322384Z",
     "iopub.status.busy": "2025-07-17T10:48:51.322110Z",
     "iopub.status.idle": "2025-07-17T10:48:51.326253Z",
     "shell.execute_reply": "2025-07-17T10:48:51.325548Z",
     "shell.execute_reply.started": "2025-07-17T10:48:51.322361Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Training sentences generations\n",
    "SPEAKER_REFERENCE = [\n",
    "    \"/kaggle/input/the-lj-speech-dataset/LJSpeech-1.1/wavs/LJ001-0001.wav\"  # speaker reference to be used in training test sentences\n",
    "]\n",
    "LANGUAGE = config_dataset.language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Аргументы модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:48:52.870282Z",
     "iopub.status.busy": "2025-07-17T10:48:52.870024Z",
     "iopub.status.idle": "2025-07-17T10:48:52.874988Z",
     "shell.execute_reply": "2025-07-17T10:48:52.874190Z",
     "shell.execute_reply.started": "2025-07-17T10:48:52.870263Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_args = GPTArgs(\n",
    "        max_conditioning_length=198450,  # 9 secs\n",
    "        min_conditioning_length=66150,  # 3 secs\n",
    "        debug_loading_failures=False,\n",
    "        max_wav_length=255995,  # ~11.6 seconds\n",
    "        max_text_length=200,\n",
    "        mel_norm_file=MEL_NORM_FILE,\n",
    "        dvae_checkpoint=DVAE_CHECKPOINT,\n",
    "        xtts_checkpoint=XTTS_CHECKPOINT,  # checkpoint path of the model that you want to fine-tune\n",
    "        tokenizer_file=TOKENIZER_FILE,\n",
    "        gpt_num_audio_tokens=1026,\n",
    "        gpt_start_audio_token=1024,\n",
    "        gpt_stop_audio_token=1025,\n",
    "        gpt_use_masking_gt_prompt_approach=True,\n",
    "        gpt_use_perceiver_resampler=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:49:00.008145Z",
     "iopub.status.busy": "2025-07-17T10:49:00.007592Z",
     "iopub.status.idle": "2025-07-17T10:49:00.011646Z",
     "shell.execute_reply": "2025-07-17T10:49:00.010826Z",
     "shell.execute_reply.started": "2025-07-17T10:49:00.008121Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "audio_config = XttsAudioConfig(sample_rate=22050, dvae_sample_rate=22050, output_sample_rate=24000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Конфигурация обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:49:03.525940Z",
     "iopub.status.busy": "2025-07-17T10:49:03.525026Z",
     "iopub.status.idle": "2025-07-17T10:49:03.529295Z",
     "shell.execute_reply": "2025-07-17T10:49:03.528631Z",
     "shell.execute_reply.started": "2025-07-17T10:49:03.525902Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Logging parameters\n",
    "RUN_NAME = \"GPT_XTTS_v2.0_LJSpeech_FT\"\n",
    "PROJECT_NAME = \"XTTS_trainer\"\n",
    "DASHBOARD_LOGGER = \"tensorboard\"\n",
    "LOGGER_URI = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:49:08.535394Z",
     "iopub.status.busy": "2025-07-17T10:49:08.535132Z",
     "iopub.status.idle": "2025-07-17T10:49:19.396154Z",
     "shell.execute_reply": "2025-07-17T10:49:19.395542Z",
     "shell.execute_reply.started": "2025-07-17T10:49:08.535375Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> DVAE weights restored from: /kaggle/working/run/XTTS_v2.0_original_model_files/dvae.pth\n"
     ]
    }
   ],
   "source": [
    "config = GPTTrainerConfig(\n",
    "        epochs = 5,\n",
    "        run_eval = True,\n",
    "        output_path=OUT_PATH,\n",
    "        model_args=model_args,\n",
    "        run_name=RUN_NAME,\n",
    "        project_name=PROJECT_NAME,\n",
    "        run_description=\"\"\"\n",
    "            GPT XTTS training\n",
    "            \"\"\",\n",
    "        dashboard_logger=DASHBOARD_LOGGER,\n",
    "        logger_uri=LOGGER_URI,\n",
    "        audio=audio_config,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        batch_group_size=48,\n",
    "        eval_batch_size=BATCH_SIZE,\n",
    "        num_loader_workers=4,\n",
    "        eval_split_max_size=256,\n",
    "        print_step=50,\n",
    "        plot_step=100,\n",
    "        log_model_step=1000,\n",
    "        save_step=5000,\n",
    "        save_n_checkpoints=1,\n",
    "        save_checkpoints=True,\n",
    "        # target_loss=\"loss\",\n",
    "        print_eval=False,\n",
    "        # Optimizer values like tortoise, pytorch implementation with modifications to not apply WD to non-weight parameters.\n",
    "        optimizer=\"AdamW\",\n",
    "        optimizer_wd_only_on_weights=OPTIMIZER_WD_ONLY_ON_WEIGHTS,\n",
    "        optimizer_params={\"betas\": [0.9, 0.96], \"eps\": 1e-8, \"weight_decay\": 1e-2},\n",
    "        lr=5e-06,  # learning rate\n",
    "        lr_scheduler=\"MultiStepLR\",\n",
    "        # it was adjusted accordly for the new step scheme\n",
    "        lr_scheduler_params={\"milestones\": [50000 * 18, 150000 * 18, 300000 * 18], \"gamma\": 0.5, \"last_epoch\": -1},\n",
    "        test_sentences=[\n",
    "            {\n",
    "                \"text\": \"It took me quite a long time to develop a voice, and now that I have it I'm not going to be silent.\",\n",
    "                \"speaker_wav\": SPEAKER_REFERENCE,\n",
    "                \"language\": LANGUAGE,\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"This cake is great. It's so delicious and moist.\",\n",
    "                \"speaker_wav\": SPEAKER_REFERENCE,\n",
    "                \"language\": LANGUAGE,\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "\n",
    "model = GPTTrainer.init_from_config(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:49:25.758966Z",
     "iopub.status.busy": "2025-07-17T10:49:25.758048Z",
     "iopub.status.idle": "2025-07-17T10:49:25.917984Z",
     "shell.execute_reply": "2025-07-17T10:49:25.917163Z",
     "shell.execute_reply.started": "2025-07-17T10:49:25.758939Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Found 13100 files in /kaggle/input/the-lj-speech-dataset/LJSpeech-1.1\n"
     ]
    }
   ],
   "source": [
    "train_samples, eval_samples = load_tts_samples(config_dataset, eval_split=True, eval_split_size=0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-07-17T10:49:36.243090Z",
     "iopub.status.busy": "2025-07-17T10:49:36.242576Z",
     "iopub.status.idle": "2025-07-17T11:29:06.959110Z",
     "shell.execute_reply": "2025-07-17T11:29:06.956531Z",
     "shell.execute_reply.started": "2025-07-17T10:49:36.243065Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: not a git repository (or any parent up to mount point /kaggle)\n",
      "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
      "fatal: not a git repository (or any parent up to mount point /kaggle)\n",
      "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
      " > Training Environment:\n",
      " | > Backend: Torch\n",
      " | > Mixed precision: False\n",
      " | > Precision: float32\n",
      " | > Current device: 0\n",
      " | > Num. of GPUs: 1\n",
      " | > Num. of CPUs: 4\n",
      " | > Num. of Torch Threads: 1\n",
      " | > Torch seed: 1\n",
      " | > Torch CUDNN: True\n",
      " | > Torch CUDNN deterministic: False\n",
      " | > Torch CUDNN benchmark: False\n",
      " | > Torch TF32 MatMul: False\n",
      "2025-07-17 10:49:37.872889: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1752749378.047516      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1752749378.097034      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      " > Start Tensorboard: tensorboard --logdir=/kaggle/working/run/GPT_XTTS_v2.0_LJSpeech_FT-July-17-2025_10+49AM-0000000\n",
      "\n",
      " > Model has 518442047 parameters\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 0/5\u001b[0m\n",
      " --> /kaggle/working/run/GPT_XTTS_v2.0_LJSpeech_FT-July-17-2025_10+49AM-0000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Filtering invalid eval samples!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Total eval samples after filtering: 262\n",
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time: 0.058132039583646336 \u001b[0m(+0)\n",
      "     | > avg_loss_text_ce: 0.02300384864211083 \u001b[0m(+0)\n",
      "     | > avg_loss_mel_ce: 3.6739199308248667 \u001b[0m(+0)\n",
      "     | > avg_loss: 3.696923776773306 \u001b[0m(+0)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 1/5\u001b[0m\n",
      " --> /kaggle/working/run/GPT_XTTS_v2.0_LJSpeech_FT-July-17-2025_10+49AM-0000000\n",
      "\n",
      "\u001b[1m > TRAINING (2025-07-17 10:50:31) \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Sampling by language: dict_keys(['en'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 10:50:33 -- STEP: 0/6419 -- GLOBAL_STEP: 0\u001b[0m\n",
      "     | > loss_text_ce: 0.02335914969444275  (0.02335914969444275)\n",
      "     | > loss_mel_ce: 3.715486764907837  (3.715486764907837)\n",
      "     | > loss: 0.05841946601867676  (0.05841946601867676)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.3312  (0.3312394618988037)\n",
      "     | > loader_time: 1.4349  (1.4348711967468262)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 10:50:52 -- STEP: 50/6419 -- GLOBAL_STEP: 50\u001b[0m\n",
      "     | > loss_text_ce: 0.022206701338291168  (0.024238972142338753)\n",
      "     | > loss_mel_ce: 3.8040578365325928  (3.7184663009643555)\n",
      "     | > loss: 0.0597853846848011  (0.05847976982593536)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2644  (0.24202992439270019)\n",
      "     | > loader_time: 0.0087  (0.010888595581054688)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 10:51:11 -- STEP: 100/6419 -- GLOBAL_STEP: 100\u001b[0m\n",
      "     | > loss_text_ce: 0.020164813846349716  (0.02376967852935195)\n",
      "     | > loss_mel_ce: 3.466541051864624  (3.7050228404998777)\n",
      "     | > loss: 0.054479777812957764  (0.05826238308101892)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2449  (0.244049711227417)\n",
      "     | > loader_time: 0.0101  (0.010806720256805418)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 10:51:30 -- STEP: 150/6419 -- GLOBAL_STEP: 150\u001b[0m\n",
      "     | > loss_text_ce: 0.026547905057668686  (0.023873707205057146)\n",
      "     | > loss_mel_ce: 3.5189127922058105  (3.6497972265879315)\n",
      "     | > loss: 0.055397823452949524  (0.05740110836923122)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.296  (0.24528380393981933)\n",
      "     | > loader_time: 0.0117  (0.010572497049967447)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 10:51:49 -- STEP: 200/6419 -- GLOBAL_STEP: 200\u001b[0m\n",
      "     | > loss_text_ce: 0.022151682525873184  (0.0238999777007848)\n",
      "     | > loss_mel_ce: 3.618809223175049  (3.605755661725998)\n",
      "     | > loss: 0.05689001455903053  (0.05671336935833096)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.1827  (0.24656085371971131)\n",
      "     | > loader_time: 0.0107  (0.010406495332717895)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 10:52:08 -- STEP: 250/6419 -- GLOBAL_STEP: 250\u001b[0m\n",
      "     | > loss_text_ce: 0.026257235556840897  (0.02385430361330509)\n",
      "     | > loss_mel_ce: 3.577317714691162  (3.5736222429275513)\n",
      "     | > loss: 0.05630585923790932  (0.05621057108044624)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2906  (0.24669715881347656)\n",
      "     | > loader_time: 0.0089  (0.010236709594726563)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 10:52:27 -- STEP: 300/6419 -- GLOBAL_STEP: 300\u001b[0m\n",
      "     | > loss_text_ce: 0.02265038713812828  (0.02385537757227818)\n",
      "     | > loss_mel_ce: 3.4510350227355957  (3.5437725512186686)\n",
      "     | > loss: 0.05427633598446846  (0.055744186465938886)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2898  (0.24657601992289224)\n",
      "     | > loader_time: 0.0082  (0.01009120146433512)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 10:52:47 -- STEP: 350/6419 -- GLOBAL_STEP: 350\u001b[0m\n",
      "     | > loss_text_ce: 0.022714056074619293  (0.023861346526869696)\n",
      "     | > loss_mel_ce: 3.6319501399993896  (3.5140758895874025)\n",
      "     | > loss: 0.05710412934422493  (0.05528026936309678)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2914  (0.24712102685655865)\n",
      "     | > loader_time: 0.009  (0.009972782816205701)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 10:53:06 -- STEP: 400/6419 -- GLOBAL_STEP: 400\u001b[0m\n",
      "     | > loss_text_ce: 0.022248778492212296  (0.023830262194387605)\n",
      "     | > loss_mel_ce: 3.085216760635376  (3.491706067919731)\n",
      "     | > loss: 0.04855414852499962  (0.054930255208164455)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2124  (0.24758848369121553)\n",
      "     | > loader_time: 0.0087  (0.009869185686111446)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 10:53:25 -- STEP: 450/6419 -- GLOBAL_STEP: 450\u001b[0m\n",
      "     | > loss_text_ce: 0.02520308643579483  (0.02383144727597633)\n",
      "     | > loss_mel_ce: 3.363375186920166  (3.4701466359032525)\n",
      "     | > loss: 0.052946534007787704  (0.054593407586216926)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2626  (0.2464131408267551)\n",
      "     | > loader_time: 0.0081  (0.009806702931721999)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 10:53:44 -- STEP: 500/6419 -- GLOBAL_STEP: 500\u001b[0m\n",
      "     | > loss_text_ce: 0.025856653228402138  (0.023794524818658822)\n",
      "     | > loss_mel_ce: 3.31957745552063  (3.448655472278595)\n",
      "     | > loss: 0.052272409200668335  (0.05425703121721744)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2626  (0.24652927589416504)\n",
      "     | > loader_time: 0.0086  (0.009762909889221186)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 10:54:03 -- STEP: 550/6419 -- GLOBAL_STEP: 550\u001b[0m\n",
      "     | > loss_text_ce: 0.02681497298181057  (0.023833407884971656)\n",
      "     | > loss_mel_ce: 3.0863559246063232  (3.4280068141763866)\n",
      "     | > loss: 0.04864329472184181  (0.05393500346351754)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2691  (0.24661754218014803)\n",
      "     | > loader_time: 0.0102  (0.009699310822920358)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 10:54:22 -- STEP: 600/6419 -- GLOBAL_STEP: 600\u001b[0m\n",
      "     | > loss_text_ce: 0.02704048529267311  (0.023871456552296874)\n",
      "     | > loss_mel_ce: 2.949673652648926  (3.4098623756567643)\n",
      "     | > loss: 0.04651115834712982  (0.053652091125647214)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2965  (0.2472037096818288)\n",
      "     | > loader_time: 0.0083  (0.009641191164652499)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 10:54:42 -- STEP: 650/6419 -- GLOBAL_STEP: 650\u001b[0m\n",
      "     | > loss_text_ce: 0.020179077982902527  (0.023883164573747385)\n",
      "     | > loss_mel_ce: 3.2353477478027344  (3.3944662299522994)\n",
      "     | > loss: 0.050867605954408646  (0.05341170928799188)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2884  (0.24756532962505634)\n",
      "     | > loader_time: 0.0079  (0.009593497789823085)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 10:55:00 -- STEP: 700/6419 -- GLOBAL_STEP: 700\u001b[0m\n",
      "     | > loss_text_ce: 0.021333685144782066  (0.02384435178712011)\n",
      "     | > loss_mel_ce: 3.018779754638672  (3.377898469993047)\n",
      "     | > loss: 0.04750177264213562  (0.05315223160066774)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2656  (0.2470771861076355)\n",
      "     | > loader_time: 0.0082  (0.009565275737217478)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 10:55:19 -- STEP: 750/6419 -- GLOBAL_STEP: 750\u001b[0m\n",
      "     | > loss_text_ce: 0.02374204620718956  (0.02384613882998626)\n",
      "     | > loss_mel_ce: 3.211186170578003  (3.36282410812378)\n",
      "     | > loss: 0.05054575204849243  (0.052916722625493996)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2108  (0.24690589650472006)\n",
      "     | > loader_time: 0.0081  (0.009527338663736968)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 10:55:38 -- STEP: 800/6419 -- GLOBAL_STEP: 800\u001b[0m\n",
      "     | > loss_text_ce: 0.021545249968767166  (0.023817587383091456)\n",
      "     | > loss_mel_ce: 2.909982681274414  (3.3489725634455687)\n",
      "     | > loss: 0.04580512270331383  (0.052699846122413865)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2596  (0.24636347472667694)\n",
      "     | > loader_time: 0.0078  (0.009494206309318527)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 10:55:56 -- STEP: 850/6419 -- GLOBAL_STEP: 850\u001b[0m\n",
      "     | > loss_text_ce: 0.02785376086831093  (0.023831265467931247)\n",
      "     | > loss_mel_ce: 3.3004953861236572  (3.3359045858944167)\n",
      "     | > loss: 0.052005454897880554  (0.052495872693903295)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.247  (0.24569801583009607)\n",
      "     | > loader_time: 0.0079  (0.009469536052030658)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 10:56:15 -- STEP: 900/6419 -- GLOBAL_STEP: 900\u001b[0m\n",
      "     | > loss_text_ce: 0.025279933586716652  (0.023838789645168522)\n",
      "     | > loss_mel_ce: 3.1854021549224854  (3.3233308060963953)\n",
      "     | > loss: 0.05016690865159035  (0.05229952495131227)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2059  (0.24565810124079387)\n",
      "     | > loader_time: 0.0077  (0.00942091544469196)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 10:56:33 -- STEP: 950/6419 -- GLOBAL_STEP: 950\u001b[0m\n",
      "     | > loss_text_ce: 0.02613290213048458  (0.023828266670829375)\n",
      "     | > loss_mel_ce: 3.0031118392944336  (3.311943330764771)\n",
      "     | > loss: 0.04733194783329964  (0.05212143123149871)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.1901  (0.24507439236891898)\n",
      "     | > loader_time: 0.0103  (0.009382978489524425)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 10:56:53 -- STEP: 1000/6419 -- GLOBAL_STEP: 1000\u001b[0m\n",
      "     | > loss_text_ce: 0.027615483850240707  (0.02382099707052112)\n",
      "     | > loss_mel_ce: 2.841623306274414  (3.3011309869289405)\n",
      "     | > loss: 0.044831857085227966  (0.05195237476751208)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2628  (0.2452991509437561)\n",
      "     | > loader_time: 0.008  (0.009347276210784898)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 10:57:11 -- STEP: 1050/6419 -- GLOBAL_STEP: 1050\u001b[0m\n",
      "     | > loss_text_ce: 0.02467699721455574  (0.02383005118973199)\n",
      "     | > loss_mel_ce: 3.029615640640259  (3.289804907299224)\n",
      "     | > loss: 0.04772332310676575  (0.05177554625840414)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2442  (0.24513447806948707)\n",
      "     | > loader_time: 0.008  (0.009308796837216318)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 10:57:30 -- STEP: 1100/6419 -- GLOBAL_STEP: 1100\u001b[0m\n",
      "     | > loss_text_ce: 0.021366029977798462  (0.02384101207622073)\n",
      "     | > loss_mel_ce: 2.8579390048980713  (3.2797411188212333)\n",
      "     | > loss: 0.04498914256691933  (0.051618470834060154)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2667  (0.24522308436307041)\n",
      "     | > loader_time: 0.009  (0.009281615343960834)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 10:57:49 -- STEP: 1150/6419 -- GLOBAL_STEP: 1150\u001b[0m\n",
      "     | > loss_text_ce: 0.020747078582644463  (0.023829214318614945)\n",
      "     | > loss_mel_ce: 3.0453383922576904  (3.2707542315773352)\n",
      "     | > loss: 0.04790758714079857  (0.05147786638658981)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2233  (0.24496824057205863)\n",
      "     | > loader_time: 0.0089  (0.009256949424743637)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 10:58:08 -- STEP: 1200/6419 -- GLOBAL_STEP: 1200\u001b[0m\n",
      "     | > loss_text_ce: 0.023201679810881615  (0.02383125821594149)\n",
      "     | > loss_mel_ce: 2.9837124347686768  (3.261471105416617)\n",
      "     | > loss: 0.046983033418655396  (0.051332849469035914)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2897  (0.24496059715747834)\n",
      "     | > loader_time: 0.0083  (0.009235414862632739)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 10:58:26 -- STEP: 1250/6419 -- GLOBAL_STEP: 1250\u001b[0m\n",
      "     | > loss_text_ce: 0.02582368068397045  (0.023814152443408967)\n",
      "     | > loss_mel_ce: 2.9220082759857178  (3.25225097808838)\n",
      "     | > loss: 0.04605987295508385  (0.051188517710566546)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2585  (0.24458179531097413)\n",
      "     | > loader_time: 0.0082  (0.0092074773788452)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 10:58:45 -- STEP: 1300/6419 -- GLOBAL_STEP: 1300\u001b[0m\n",
      "     | > loss_text_ce: 0.022240590304136276  (0.023809090379912128)\n",
      "     | > loss_mel_ce: 2.917529821395874  (3.243624526537383)\n",
      "     | > loss: 0.04593391343951225  (0.051053650307540735)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2652  (0.24465270317517795)\n",
      "     | > loader_time: 0.0091  (0.009187896435077362)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 10:59:04 -- STEP: 1350/6419 -- GLOBAL_STEP: 1350\u001b[0m\n",
      "     | > loss_text_ce: 0.021591389551758766  (0.0238211318505583)\n",
      "     | > loss_mel_ce: 2.9261722564697266  (3.2350390580848423)\n",
      "     | > loss: 0.04605880752205849  (0.05091969050191069)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.1887  (0.24463701336472124)\n",
      "     | > loader_time: 0.0088  (0.00918225235409206)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 10:59:23 -- STEP: 1400/6419 -- GLOBAL_STEP: 1400\u001b[0m\n",
      "     | > loss_text_ce: 0.0223263967782259  (0.023798455814165728)\n",
      "     | > loss_mel_ce: 2.996934652328491  (3.2282876975195762)\n",
      "     | > loss: 0.04717595502734184  (0.050813846191657464)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2657  (0.24450083528246197)\n",
      "     | > loader_time: 0.0081  (0.00916130185127258)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 10:59:42 -- STEP: 1450/6419 -- GLOBAL_STEP: 1450\u001b[0m\n",
      "     | > loss_text_ce: 0.025529377162456512  (0.023781393820355677)\n",
      "     | > loss_mel_ce: 2.9546473026275635  (3.220795165094837)\n",
      "     | > loss: 0.046565260738134384  (0.050696508781663326)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2422  (0.2444625892310307)\n",
      "     | > loader_time: 0.0082  (0.009138871390244043)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:00:01 -- STEP: 1500/6419 -- GLOBAL_STEP: 1500\u001b[0m\n",
      "     | > loss_text_ce: 0.025307191535830498  (0.023785207957029344)\n",
      "     | > loss_mel_ce: 2.9005653858184814  (3.214240436077119)\n",
      "     | > loss: 0.04571675881743431  (0.05059415072947743)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2085  (0.24464792569478352)\n",
      "     | > loader_time: 0.008  (0.009117121378580718)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:00:19 -- STEP: 1550/6419 -- GLOBAL_STEP: 1550\u001b[0m\n",
      "     | > loss_text_ce: 0.021824778988957405  (0.023770697394446018)\n",
      "     | > loss_mel_ce: 2.9605116844177246  (3.2088663454978708)\n",
      "     | > loss: 0.04659900814294815  (0.0505099538377216)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.269  (0.24447850104301205)\n",
      "     | > loader_time: 0.0082  (0.009108741206507516)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:00:39 -- STEP: 1600/6419 -- GLOBAL_STEP: 1600\u001b[0m\n",
      "     | > loss_text_ce: 0.02618349902331829  (0.023768674042075874)\n",
      "     | > loss_mel_ce: 3.0534589290618896  (3.202506216913463)\n",
      "     | > loss: 0.04811941459774971  (0.05041054521221669)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2222  (0.2446051348745823)\n",
      "     | > loader_time: 0.0097  (0.009097400605678542)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:00:58 -- STEP: 1650/6419 -- GLOBAL_STEP: 1650\u001b[0m\n",
      "     | > loss_text_ce: 0.025747857987880707  (0.02374916633873275)\n",
      "     | > loss_mel_ce: 3.1223220825195312  (3.196524078773731)\n",
      "     | > loss: 0.04918859153985977  (0.050316769489736284)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2659  (0.24472694093530828)\n",
      "     | > loader_time: 0.0085  (0.009079342177419942)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:01:17 -- STEP: 1700/6419 -- GLOBAL_STEP: 1700\u001b[0m\n",
      "     | > loss_text_ce: 0.022217614576220512  (0.02373702285263468)\n",
      "     | > loss_mel_ce: 3.076479911804199  (3.190629808061264)\n",
      "     | > loss: 0.04841714724898338  (0.05022448176846787)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.1604  (0.24472477856804342)\n",
      "     | > loader_time: 0.0104  (0.00906139906714943)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:01:35 -- STEP: 1750/6419 -- GLOBAL_STEP: 1750\u001b[0m\n",
      "     | > loss_text_ce: 0.019948597997426987  (0.023712767492447582)\n",
      "     | > loss_mel_ce: 3.066851854324341  (3.1847647252764033)\n",
      "     | > loss: 0.048231255263090134  (0.05013246085601195)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2612  (0.24466955607278007)\n",
      "     | > loader_time: 0.008  (0.009043282372610895)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:01:54 -- STEP: 1800/6419 -- GLOBAL_STEP: 1800\u001b[0m\n",
      "     | > loss_text_ce: 0.024103336036205292  (0.023717527037693396)\n",
      "     | > loss_mel_ce: 2.9262077808380127  (3.1786494886875163)\n",
      "     | > loss: 0.04609861224889755  (0.050036984644830244)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2247  (0.24466063234541152)\n",
      "     | > loader_time: 0.0079  (0.009029281006918993)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:02:13 -- STEP: 1850/6419 -- GLOBAL_STEP: 1850\u001b[0m\n",
      "     | > loss_text_ce: 0.02456427551805973  (0.02371646481188568)\n",
      "     | > loss_mel_ce: 3.032517433166504  (3.173120654209241)\n",
      "     | > loss: 0.047766901552677155  (0.04995058000893208)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2932  (0.24466594915132264)\n",
      "     | > loader_time: 0.0086  (0.009018059550104896)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:02:32 -- STEP: 1900/6419 -- GLOBAL_STEP: 1900\u001b[0m\n",
      "     | > loss_text_ce: 0.027101237326860428  (0.023734365092884555)\n",
      "     | > loss_mel_ce: 2.998448133468628  (3.16839527054837)\n",
      "     | > loss: 0.047274209558963776  (0.04987702557915137)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.1897  (0.24461085997129742)\n",
      "     | > loader_time: 0.01  (0.009005462495904202)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:02:51 -- STEP: 1950/6419 -- GLOBAL_STEP: 1950\u001b[0m\n",
      "     | > loss_text_ce: 0.02172817662358284  (0.023720876762691218)\n",
      "     | > loss_mel_ce: 2.9974238872528076  (3.163469557150817)\n",
      "     | > loss: 0.047174252569675446  (0.04979985055251001)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2967  (0.24467474802946432)\n",
      "     | > loader_time: 0.0081  (0.008993929227193179)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:03:11 -- STEP: 2000/6419 -- GLOBAL_STEP: 2000\u001b[0m\n",
      "     | > loss_text_ce: 0.025003010407090187  (0.02369971527904272)\n",
      "     | > loss_mel_ce: 3.0588979721069336  (3.1593372811079035)\n",
      "     | > loss: 0.04818595200777054  (0.04973495308868588)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2135  (0.24494296741485597)\n",
      "     | > loader_time: 0.0102  (0.00898663640022276)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:03:30 -- STEP: 2050/6419 -- GLOBAL_STEP: 2050\u001b[0m\n",
      "     | > loss_text_ce: 0.025652408599853516  (0.02368249648591367)\n",
      "     | > loss_mel_ce: 3.0134928226470947  (3.155678635341366)\n",
      "     | > loss: 0.047486644238233566  (0.04967751770121297)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2923  (0.2450586370142495)\n",
      "     | > loader_time: 0.0085  (0.008981883467697498)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:03:49 -- STEP: 2100/6419 -- GLOBAL_STEP: 2100\u001b[0m\n",
      "     | > loss_text_ce: 0.021295828744769096  (0.023663970858213448)\n",
      "     | > loss_mel_ce: 3.0207982063293457  (3.151554347219922)\n",
      "     | > loss: 0.04753271862864494  (0.04961278623768263)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2701  (0.2451051844869341)\n",
      "     | > loader_time: 0.0078  (0.008963527565910685)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:04:08 -- STEP: 2150/6419 -- GLOBAL_STEP: 2150\u001b[0m\n",
      "     | > loss_text_ce: 0.023499978706240654  (0.02365073813775251)\n",
      "     | > loss_mel_ce: 2.6535298824310303  (3.14754106122394)\n",
      "     | > loss: 0.041828591376543045  (0.049549871882380456)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.269  (0.24512833029724831)\n",
      "     | > loader_time: 0.008  (0.008951413575993019)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:04:27 -- STEP: 2200/6419 -- GLOBAL_STEP: 2200\u001b[0m\n",
      "     | > loss_text_ce: 0.02420925535261631  (0.023635410985655407)\n",
      "     | > loss_mel_ce: 2.8658013343811035  (3.142875123349105)\n",
      "     | > loss: 0.045156415551900864  (0.04947672710669313)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2895  (0.24509729634631763)\n",
      "     | > loader_time: 0.0087  (0.00894251108169555)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:04:46 -- STEP: 2250/6419 -- GLOBAL_STEP: 2250\u001b[0m\n",
      "     | > loss_text_ce: 0.02302996814250946  (0.023632267629934672)\n",
      "     | > loss_mel_ce: 2.992154836654663  (3.1385545431772885)\n",
      "     | > loss: 0.04711226373910904  (0.04940916893217301)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.1901  (0.24526235749986436)\n",
      "     | > loader_time: 0.0083  (0.00893285083770751)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:05:04 -- STEP: 2300/6419 -- GLOBAL_STEP: 2300\u001b[0m\n",
      "     | > loss_text_ce: 0.02304779924452305  (0.023638463920873137)\n",
      "     | > loss_mel_ce: 2.996100425720215  (3.1344592794128103)\n",
      "     | > loss: 0.04717418923974037  (0.04934527724819341)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2362  (0.24501523359962132)\n",
      "     | > loader_time: 0.0082  (0.008924583974091892)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:05:23 -- STEP: 2350/6419 -- GLOBAL_STEP: 2350\u001b[0m\n",
      "     | > loss_text_ce: 0.018883850425481796  (0.023631646078317713)\n",
      "     | > loss_mel_ce: 2.9683191776275635  (3.13040155847022)\n",
      "     | > loss: 0.046675048768520355  (0.04928176883053274)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2925  (0.2448488948700276)\n",
      "     | > loader_time: 0.0098  (0.008919673879095837)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:05:42 -- STEP: 2400/6419 -- GLOBAL_STEP: 2400\u001b[0m\n",
      "     | > loss_text_ce: 0.02402304671704769  (0.023623348478383068)\n",
      "     | > loss_mel_ce: 2.951780319213867  (3.127140348951024)\n",
      "     | > loss: 0.0464969277381897  (0.04923068278003482)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.265  (0.24496743907531102)\n",
      "     | > loader_time: 0.0091  (0.008911432921886434)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:06:01 -- STEP: 2450/6419 -- GLOBAL_STEP: 2450\u001b[0m\n",
      "     | > loss_text_ce: 0.024859203025698662  (0.02361707963201463)\n",
      "     | > loss_mel_ce: 2.9816830158233643  (3.123997368909876)\n",
      "     | > loss: 0.046977221965789795  (0.049181475768588015)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2635  (0.2448698294892603)\n",
      "     | > loader_time: 0.009  (0.008907802153606793)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:06:20 -- STEP: 2500/6419 -- GLOBAL_STEP: 2500\u001b[0m\n",
      "     | > loss_text_ce: 0.025009317323565483  (0.023617245054990035)\n",
      "     | > loss_mel_ce: 2.8219997882843018  (3.120969460296632)\n",
      "     | > loss: 0.044484518468379974  (0.049134167282283286)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.186  (0.24495168075561524)\n",
      "     | > loader_time: 0.0077  (0.0088976613998413)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:06:39 -- STEP: 2550/6419 -- GLOBAL_STEP: 2550\u001b[0m\n",
      "     | > loss_text_ce: 0.020747724920511246  (0.023598301317177557)\n",
      "     | > loss_mel_ce: 3.2410566806793213  (3.1174633975122514)\n",
      "     | > loss: 0.05096569284796715  (0.04907908906101009)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2449  (0.24501205229291728)\n",
      "     | > loader_time: 0.0079  (0.008887592390471806)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:06:58 -- STEP: 2600/6419 -- GLOBAL_STEP: 2600\u001b[0m\n",
      "     | > loss_text_ce: 0.023120585829019547  (0.02359966546655274)\n",
      "     | > loss_mel_ce: 2.905827522277832  (3.1138905054789356)\n",
      "     | > loss: 0.04576481506228447  (0.04902328393636986)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2493  (0.24507098867343022)\n",
      "     | > loader_time: 0.0084  (0.008885694650503298)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:07:17 -- STEP: 2650/6419 -- GLOBAL_STEP: 2650\u001b[0m\n",
      "     | > loss_text_ce: 0.02315390482544899  (0.0235950164201687)\n",
      "     | > loss_mel_ce: 2.836822271347046  (3.1106731027027386)\n",
      "     | > loss: 0.04468712955713272  (0.04897293937656112)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2445  (0.24515917930962905)\n",
      "     | > loader_time: 0.0081  (0.008879824224508025)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:07:37 -- STEP: 2700/6419 -- GLOBAL_STEP: 2700\u001b[0m\n",
      "     | > loss_text_ce: 0.020189497619867325  (0.02358650628960244)\n",
      "     | > loss_mel_ce: 2.892603874206543  (3.107027261257176)\n",
      "     | > loss: 0.04551239684224129  (0.04891584012933349)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2925  (0.24525071788717198)\n",
      "     | > loader_time: 0.0082  (0.008871273111414021)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:07:55 -- STEP: 2750/6419 -- GLOBAL_STEP: 2750\u001b[0m\n",
      "     | > loss_text_ce: 0.019595671445131302  (0.02358057394488293)\n",
      "     | > loss_mel_ce: 2.9720704555511475  (3.104180951378566)\n",
      "     | > loss: 0.046744782477617264  (0.04887127384543417)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2146  (0.24521440029144287)\n",
      "     | > loader_time: 0.008  (0.008862023440274315)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:08:14 -- STEP: 2800/6419 -- GLOBAL_STEP: 2800\u001b[0m\n",
      "     | > loss_text_ce: 0.025451378896832466  (0.02357958606843439)\n",
      "     | > loss_mel_ce: 2.6557986736297607  (3.1014986549105004)\n",
      "     | > loss: 0.04189453274011612  (0.04882934752984769)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2592  (0.24513525128364563)\n",
      "     | > loader_time: 0.008  (0.008858274647167732)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:08:33 -- STEP: 2850/6419 -- GLOBAL_STEP: 2850\u001b[0m\n",
      "     | > loss_text_ce: 0.026255032047629356  (0.023575575523601306)\n",
      "     | > loss_mel_ce: 2.9541685581207275  (3.0980278838308273)\n",
      "     | > loss: 0.04656912013888359  (0.04877505406606614)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2522  (0.2450327534424631)\n",
      "     | > loader_time: 0.0088  (0.008855499802974218)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:08:51 -- STEP: 2900/6419 -- GLOBAL_STEP: 2900\u001b[0m\n",
      "     | > loss_text_ce: 0.022853147238492966  (0.023575857266269897)\n",
      "     | > loss_mel_ce: 2.8758602142333984  (3.094473632368552)\n",
      "     | > loss: 0.04529239609837532  (0.048719523293447885)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2533  (0.24495174440844306)\n",
      "     | > loader_time: 0.0084  (0.00885195181287567)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:09:10 -- STEP: 2950/6419 -- GLOBAL_STEP: 2950\u001b[0m\n",
      "     | > loss_text_ce: 0.02279042825102806  (0.02357787483135019)\n",
      "     | > loss_mel_ce: 2.8953356742858887  (3.0906804998850457)\n",
      "     | > loss: 0.045595720410346985  (0.0486602871258885)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2128  (0.24495986938476563)\n",
      "     | > loader_time: 0.0096  (0.00884314189522953)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:09:29 -- STEP: 3000/6419 -- GLOBAL_STEP: 3000\u001b[0m\n",
      "     | > loss_text_ce: 0.022277235984802246  (0.023580412680904085)\n",
      "     | > loss_mel_ce: 3.1056413650512695  (3.0877822990417516)\n",
      "     | > loss: 0.04887373000383377  (0.04861504239464798)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2682  (0.24493348534901938)\n",
      "     | > loader_time: 0.0085  (0.008839193423589062)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:09:48 -- STEP: 3050/6419 -- GLOBAL_STEP: 3050\u001b[0m\n",
      "     | > loss_text_ce: 0.025411104783415794  (0.02357313730921903)\n",
      "     | > loss_mel_ce: 3.175466775894165  (3.084735549160695)\n",
      "     | > loss: 0.050013717263936996  (0.04856732325231441)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2646  (0.24492350601759114)\n",
      "     | > loader_time: 0.0084  (0.008835564988558397)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:10:07 -- STEP: 3100/6419 -- GLOBAL_STEP: 3100\u001b[0m\n",
      "     | > loss_text_ce: 0.022184953093528748  (0.023568870645136616)\n",
      "     | > loss_mel_ce: 2.902313232421875  (3.0817434210931136)\n",
      "     | > loss: 0.04569528251886368  (0.048520504583514486)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2694  (0.24496428235884635)\n",
      "     | > loader_time: 0.0102  (0.008830912959191094)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:10:27 -- STEP: 3150/6419 -- GLOBAL_STEP: 3150\u001b[0m\n",
      "     | > loss_text_ce: 0.02304980717599392  (0.023564625782152977)\n",
      "     | > loss_mel_ce: 2.8876044750213623  (3.0790212756111544)\n",
      "     | > loss: 0.04547897353768349  (0.048477904735103466)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.1851  (0.24514136965312655)\n",
      "     | > loader_time: 0.0077  (0.008827974682762486)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:10:46 -- STEP: 3200/6419 -- GLOBAL_STEP: 3200\u001b[0m\n",
      "     | > loss_text_ce: 0.02005193755030632  (0.023562328106490907)\n",
      "     | > loss_mel_ce: 2.740999460220337  (3.0762227471172845)\n",
      "     | > loss: 0.043141428381204605  (0.048434141821926444)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2561  (0.24524567894637583)\n",
      "     | > loader_time: 0.0099  (0.0088262542337179)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:11:05 -- STEP: 3250/6419 -- GLOBAL_STEP: 3250\u001b[0m\n",
      "     | > loss_text_ce: 0.02123063988983631  (0.023549846442846165)\n",
      "     | > loss_mel_ce: 2.960127115249634  (3.0737295994391842)\n",
      "     | > loss: 0.046583715826272964  (0.048394991362324113)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2909  (0.24530422100654015)\n",
      "     | > loader_time: 0.0089  (0.008824428925147409)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:11:24 -- STEP: 3300/6419 -- GLOBAL_STEP: 3300\u001b[0m\n",
      "     | > loss_text_ce: 0.025033555924892426  (0.023542263539451554)\n",
      "     | > loss_mel_ce: 2.7501585483551025  (3.071412931861303)\n",
      "     | > loss: 0.04336237534880638  (0.048358674949091476)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2202  (0.24532174543900923)\n",
      "     | > loader_time: 0.0085  (0.008820996934717348)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:11:43 -- STEP: 3350/6419 -- GLOBAL_STEP: 3350\u001b[0m\n",
      "     | > loss_text_ce: 0.022418098524212837  (0.02354087098209717)\n",
      "     | > loss_mel_ce: 2.7927134037017822  (3.068962422840634)\n",
      "     | > loss: 0.043986428529024124  (0.04832036398573596)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.292  (0.2453737971320081)\n",
      "     | > loader_time: 0.0101  (0.008815142788104167)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:12:02 -- STEP: 3400/6419 -- GLOBAL_STEP: 3400\u001b[0m\n",
      "     | > loss_text_ce: 0.022790903225541115  (0.023539722248473602)\n",
      "     | > loss_mel_ce: 2.975168466567993  (3.066655853145266)\n",
      "     | > loss: 0.046843115240335464  (0.048284305884119326)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2506  (0.24521651576547063)\n",
      "     | > loader_time: 0.0085  (0.008806281580644506)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:12:21 -- STEP: 3450/6419 -- GLOBAL_STEP: 3450\u001b[0m\n",
      "     | > loss_text_ce: 0.020973309874534607  (0.02354278930179452)\n",
      "     | > loss_mel_ce: 2.9155023097991943  (3.0643962165583765)\n",
      "     | > loss: 0.04588242992758751  (0.048249046983926173)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2475  (0.245284074285756)\n",
      "     | > loader_time: 0.008  (0.008803436376046452)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:12:40 -- STEP: 3500/6419 -- GLOBAL_STEP: 3500\u001b[0m\n",
      "     | > loss_text_ce: 0.026246702298521996  (0.02354515102239593)\n",
      "     | > loss_mel_ce: 2.9470138549804688  (3.061622532095231)\n",
      "     | > loss: 0.0464571975171566  (0.048205745067979595)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2685  (0.24539702183859688)\n",
      "     | > loader_time: 0.0083  (0.00879941054752896)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:12:59 -- STEP: 3550/6419 -- GLOBAL_STEP: 3550\u001b[0m\n",
      "     | > loss_text_ce: 0.021956872195005417  (0.023539577952887823)\n",
      "     | > loss_mel_ce: 2.906459331512451  (3.0596125209163643)\n",
      "     | > loss: 0.0457565039396286  (0.04817425156668037)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2604  (0.24538833228635115)\n",
      "     | > loader_time: 0.0089  (0.008797598959694458)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:13:18 -- STEP: 3600/6419 -- GLOBAL_STEP: 3600\u001b[0m\n",
      "     | > loss_text_ce: 0.023585868999361992  (0.023529796870942758)\n",
      "     | > loss_mel_ce: 2.869831085205078  (3.0575855128632683)\n",
      "     | > loss: 0.04520963877439499  (0.048142426737273716)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2094  (0.24542097104920282)\n",
      "     | > loader_time: 0.0085  (0.008794430030716806)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:13:37 -- STEP: 3650/6419 -- GLOBAL_STEP: 3650\u001b[0m\n",
      "     | > loss_text_ce: 0.023792831227183342  (0.023521179063373244)\n",
      "     | > loss_mel_ce: 3.0014145374298096  (3.05482961922476)\n",
      "     | > loss: 0.04726886376738548  (0.04809923124435828)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.1871  (0.24527049528409356)\n",
      "     | > loader_time: 0.008  (0.008790078032506674)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:13:56 -- STEP: 3700/6419 -- GLOBAL_STEP: 3700\u001b[0m\n",
      "     | > loss_text_ce: 0.026463398709893227  (0.02351347250612202)\n",
      "     | > loss_mel_ce: 2.991652727127075  (3.053087037898402)\n",
      "     | > loss: 0.04715806618332863  (0.04807188299660745)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.1872  (0.24532945458953445)\n",
      "     | > loader_time: 0.0077  (0.008786974919808897)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:14:15 -- STEP: 3750/6419 -- GLOBAL_STEP: 3750\u001b[0m\n",
      "     | > loss_text_ce: 0.027448037639260292  (0.023504965648055088)\n",
      "     | > loss_mel_ce: 2.9509458541870117  (3.050643473434451)\n",
      "     | > loss: 0.046537403017282486  (0.04803356938163438)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2598  (0.2454986682256063)\n",
      "     | > loader_time: 0.0094  (0.008785769462585469)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:14:34 -- STEP: 3800/6419 -- GLOBAL_STEP: 3800\u001b[0m\n",
      "     | > loss_text_ce: 0.018785055726766586  (0.023505846286976818)\n",
      "     | > loss_mel_ce: 2.869107723236084  (3.0485949328071222)\n",
      "     | > loss: 0.045123323798179626  (0.04800157469550244)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.207  (0.2454864479993519)\n",
      "     | > loader_time: 0.0086  (0.008781598806381245)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:14:53 -- STEP: 3850/6419 -- GLOBAL_STEP: 3850\u001b[0m\n",
      "     | > loss_text_ce: 0.02273096702992916  (0.023504609203861142)\n",
      "     | > loss_mel_ce: 2.8165459632873535  (3.0462764704691927)\n",
      "     | > loss: 0.044363703578710556  (0.04796532939103515)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2875  (0.2454827374297303)\n",
      "     | > loader_time: 0.0085  (0.008779314462240659)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:15:12 -- STEP: 3900/6419 -- GLOBAL_STEP: 3900\u001b[0m\n",
      "     | > loss_text_ce: 0.019537251442670822  (0.023490118190932743)\n",
      "     | > loss_mel_ce: 2.9106507301330566  (3.044116245966694)\n",
      "     | > loss: 0.04578418657183647  (0.04793134945611922)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2445  (0.24539055188496908)\n",
      "     | > loader_time: 0.0082  (0.008779714352045323)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:15:31 -- STEP: 3950/6419 -- GLOBAL_STEP: 3950\u001b[0m\n",
      "     | > loss_text_ce: 0.021729325875639915  (0.02348504405421548)\n",
      "     | > loss_mel_ce: 2.817920207977295  (3.0419637502597885)\n",
      "     | > loss: 0.044369522482156754  (0.04789763742421246)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.215  (0.245392624818826)\n",
      "     | > loader_time: 0.0079  (0.008777510063557703)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:15:49 -- STEP: 4000/6419 -- GLOBAL_STEP: 4000\u001b[0m\n",
      "     | > loss_text_ce: 0.019891243427991867  (0.02347615253459663)\n",
      "     | > loss_mel_ce: 2.8095390796661377  (3.0395364021658926)\n",
      "     | > loss: 0.04420984908938408  (0.04785957117751239)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2216  (0.24530337357521056)\n",
      "     | > loader_time: 0.0081  (0.008773848891258257)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:16:08 -- STEP: 4050/6419 -- GLOBAL_STEP: 4050\u001b[0m\n",
      "     | > loss_text_ce: 0.02619776502251625  (0.023475269042415394)\n",
      "     | > loss_mel_ce: 2.7514822483062744  (3.037116038769854)\n",
      "     | > loss: 0.04340124875307083  (0.04782173919548958)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2431  (0.24518749172304882)\n",
      "     | > loader_time: 0.0081  (0.00876849321671476)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:16:27 -- STEP: 4100/6419 -- GLOBAL_STEP: 4100\u001b[0m\n",
      "     | > loss_text_ce: 0.024826642125844955  (0.023465672198955616)\n",
      "     | > loss_mel_ce: 2.8178956508636475  (3.0349385401679276)\n",
      "     | > loss: 0.04441753402352333  (0.04778756582700623)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.1678  (0.24522160390528236)\n",
      "     | > loader_time: 0.008  (0.00876175711794599)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:16:46 -- STEP: 4150/6419 -- GLOBAL_STEP: 4150\u001b[0m\n",
      "     | > loss_text_ce: 0.02074558660387993  (0.023459271065980565)\n",
      "     | > loss_mel_ce: 2.938722610473633  (3.0329388291577284)\n",
      "     | > loss: 0.04624168947339058  (0.04775622032223694)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.25  (0.24537287160574672)\n",
      "     | > loader_time: 0.0092  (0.008757350071367027)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:17:05 -- STEP: 4200/6419 -- GLOBAL_STEP: 4200\u001b[0m\n",
      "     | > loss_text_ce: 0.01991918869316578  (0.023456864427065575)\n",
      "     | > loss_mel_ce: 2.8527095317840576  (3.030583457095285)\n",
      "     | > loss: 0.0448848232626915  (0.04771938003067457)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2647  (0.245370991059712)\n",
      "     | > loader_time: 0.008  (0.00875539870489213)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:17:24 -- STEP: 4250/6419 -- GLOBAL_STEP: 4250\u001b[0m\n",
      "     | > loss_text_ce: 0.0235318373888731  (0.023453298626577166)\n",
      "     | > loss_mel_ce: 2.8621344566345215  (3.0283859060511897)\n",
      "     | > loss: 0.04508853703737259  (0.04768498757832189)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2651  (0.24529309098860796)\n",
      "     | > loader_time: 0.0084  (0.008753782440634355)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:17:43 -- STEP: 4300/6419 -- GLOBAL_STEP: 4300\u001b[0m\n",
      "     | > loss_text_ce: 0.022430410608649254  (0.02344844362763472)\n",
      "     | > loss_mel_ce: 2.7935147285461426  (3.026174818637762)\n",
      "     | > loss: 0.043999142944812775  (0.04765036348080216)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2504  (0.2452916160295176)\n",
      "     | > loader_time: 0.0083  (0.00875347004380339)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:18:02 -- STEP: 4350/6419 -- GLOBAL_STEP: 4350\u001b[0m\n",
      "     | > loss_text_ce: 0.02076440490782261  (0.023441773820454367)\n",
      "     | > loss_mel_ce: 2.9877748489379883  (3.0245396142170384)\n",
      "     | > loss: 0.04700842499732971  (0.047624709196816876)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2613  (0.2452869501333127)\n",
      "     | > loader_time: 0.0085  (0.008752429293490025)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:18:21 -- STEP: 4400/6419 -- GLOBAL_STEP: 4400\u001b[0m\n",
      "     | > loss_text_ce: 0.02632296085357666  (0.02343725497961384)\n",
      "     | > loss_mel_ce: 2.835266590118408  (3.022141798246994)\n",
      "     | > loss: 0.044712334871292114  (0.04758717271583998)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.26  (0.24531643889167093)\n",
      "     | > loader_time: 0.0084  (0.008752469203688903)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:18:39 -- STEP: 4450/6419 -- GLOBAL_STEP: 4450\u001b[0m\n",
      "     | > loss_text_ce: 0.021607868373394012  (0.02343055528368844)\n",
      "     | > loss_mel_ce: 2.818185329437256  (3.0202310286211205)\n",
      "     | > loss: 0.044371768832206726  (0.04755721225664854)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2503  (0.24525650528039825)\n",
      "     | > loader_time: 0.0094  (0.00874995703107857)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:18:58 -- STEP: 4500/6419 -- GLOBAL_STEP: 4500\u001b[0m\n",
      "     | > loss_text_ce: 0.024197041988372803  (0.02342615698733265)\n",
      "     | > loss_mel_ce: 2.824772834777832  (3.0181964521408116)\n",
      "     | > loss: 0.044515155255794525  (0.047525353273583745)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2653  (0.2452292585902744)\n",
      "     | > loader_time: 0.0088  (0.00874918286005657)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:19:17 -- STEP: 4550/6419 -- GLOBAL_STEP: 4550\u001b[0m\n",
      "     | > loss_text_ce: 0.02208799123764038  (0.02341901525732254)\n",
      "     | > loss_mel_ce: 3.1317262649536133  (3.016489997276897)\n",
      "     | > loss: 0.04927834868431091  (0.047498578328516415)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2954  (0.24524394721775264)\n",
      "     | > loader_time: 0.0086  (0.008750203415587722)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:19:37 -- STEP: 4600/6419 -- GLOBAL_STEP: 4600\u001b[0m\n",
      "     | > loss_text_ce: 0.025458678603172302  (0.023413800514181682)\n",
      "     | > loss_mel_ce: 2.9465854167938232  (3.014701992273334)\n",
      "     | > loss: 0.04643818736076355  (0.047470559273724906)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2148  (0.2453236014428346)\n",
      "     | > loader_time: 0.0082  (0.008750252257222722)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:19:56 -- STEP: 4650/6419 -- GLOBAL_STEP: 4650\u001b[0m\n",
      "     | > loss_text_ce: 0.023276526480913162  (0.023408691241776424)\n",
      "     | > loss_mel_ce: 2.911048650741577  (3.0124307326347632)\n",
      "     | > loss: 0.04584883153438568  (0.04743499100929299)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2615  (0.24531293986946023)\n",
      "     | > loader_time: 0.0086  (0.008751235674786324)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:20:15 -- STEP: 4700/6419 -- GLOBAL_STEP: 4700\u001b[0m\n",
      "     | > loss_text_ce: 0.023925824090838432  (0.023410824179807884)\n",
      "     | > loss_mel_ce: 2.7376632690429688  (3.0105588146980815)\n",
      "     | > loss: 0.04314982891082764  (0.04740577561978954)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2521  (0.24532797067723375)\n",
      "     | > loader_time: 0.0092  (0.008749979151056181)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:20:34 -- STEP: 4750/6419 -- GLOBAL_STEP: 4750\u001b[0m\n",
      "     | > loss_text_ce: 0.019158679991960526  (0.023406998991181992)\n",
      "     | > loss_mel_ce: 2.562168836593628  (3.008869778633121)\n",
      "     | > loss: 0.04033324122428894  (0.04737932466205786)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.263  (0.24543561363220215)\n",
      "     | > loader_time: 0.0085  (0.008749901169224805)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:20:53 -- STEP: 4800/6419 -- GLOBAL_STEP: 4800\u001b[0m\n",
      "     | > loss_text_ce: 0.020675839856266975  (0.023405764168516436)\n",
      "     | > loss_mel_ce: 2.9284250736236572  (3.007149020036065)\n",
      "     | > loss: 0.04607970267534256  (0.04735241851536547)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2564  (0.24545556555191675)\n",
      "     | > loader_time: 0.0084  (0.008749393671751036)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:21:12 -- STEP: 4850/6419 -- GLOBAL_STEP: 4850\u001b[0m\n",
      "     | > loss_text_ce: 0.030335111543536186  (0.023404511035103173)\n",
      "     | > loss_mel_ce: 2.9936580657958984  (3.0057435178756746)\n",
      "     | > loss: 0.047249894589185715  (0.04733043796392437)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2446  (0.24547724266642149)\n",
      "     | > loader_time: 0.0086  (0.008747652978012251)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:21:31 -- STEP: 4900/6419 -- GLOBAL_STEP: 4900\u001b[0m\n",
      "     | > loss_text_ce: 0.02055925317108631  (0.0233990978099862)\n",
      "     | > loss_mel_ce: 2.7188682556152344  (3.004040466960598)\n",
      "     | > loss: 0.042803555727005005  (0.047303743209613745)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.1881  (0.24546621478333766)\n",
      "     | > loader_time: 0.0082  (0.008747779057950402)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:21:50 -- STEP: 4950/6419 -- GLOBAL_STEP: 4950\u001b[0m\n",
      "     | > loss_text_ce: 0.02241557464003563  (0.02339463106460042)\n",
      "     | > loss_mel_ce: 2.8166897296905518  (3.002319273804177)\n",
      "     | > loss: 0.04436102136969566  (0.0472767797737109)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2447  (0.2454110085362136)\n",
      "     | > loader_time: 0.0088  (0.008747495208123733)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:22:09 -- STEP: 5000/6419 -- GLOBAL_STEP: 5000\u001b[0m\n",
      "     | > loss_text_ce: 0.026618480682373047  (0.023395005331188462)\n",
      "     | > loss_mel_ce: 2.8313887119293213  (3.000685349702839)\n",
      "     | > loss: 0.044656362384557724  (0.047251255557686035)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.265  (0.24542309260368347)\n",
      "     | > loader_time: 0.0089  (0.00874610319137575)\n",
      "\n",
      "\n",
      " > CHECKPOINT : /kaggle/working/run/GPT_XTTS_v2.0_LJSpeech_FT-July-17-2025_10+49AM-0000000/checkpoint_5000.pth\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:22:36 -- STEP: 5050/6419 -- GLOBAL_STEP: 5050\u001b[0m\n",
      "     | > loss_text_ce: 0.021151065826416016  (0.023388358994138148)\n",
      "     | > loss_mel_ce: 3.0852959156036377  (2.9990862727873453)\n",
      "     | > loss: 0.04853823408484459  (0.0472261661320629)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2688  (0.2454043973790537)\n",
      "     | > loader_time: 0.0082  (0.00874836728124337)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:22:55 -- STEP: 5100/6419 -- GLOBAL_STEP: 5100\u001b[0m\n",
      "     | > loss_text_ce: 0.02318548411130905  (0.023384105743949925)\n",
      "     | > loss_mel_ce: 2.8973822593688965  (2.9974929940934336)\n",
      "     | > loss: 0.04563387110829353  (0.047201204695830105)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2107  (0.24543165389229268)\n",
      "     | > loader_time: 0.0078  (0.008749034311257174)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:23:13 -- STEP: 5150/6419 -- GLOBAL_STEP: 5150\u001b[0m\n",
      "     | > loss_text_ce: 0.02247069776058197  (0.02337763790656064)\n",
      "     | > loss_mel_ce: 3.002612590789795  (2.9957278658579916)\n",
      "     | > loss: 0.04726692661643028  (0.047173523508663266)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2922  (0.24533113794419373)\n",
      "     | > loader_time: 0.0103  (0.008748208758900481)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:23:32 -- STEP: 5200/6419 -- GLOBAL_STEP: 5200\u001b[0m\n",
      "     | > loss_text_ce: 0.022403690963983536  (0.02337969078001783)\n",
      "     | > loss_mel_ce: 2.8747634887695312  (2.9944592647827633)\n",
      "     | > loss: 0.045268237590789795  (0.047153733690770715)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2701  (0.24531149263565358)\n",
      "     | > loader_time: 0.009  (0.008747648138266364)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:23:51 -- STEP: 5250/6419 -- GLOBAL_STEP: 5250\u001b[0m\n",
      "     | > loss_text_ce: 0.02448408491909504  (0.023379334494826348)\n",
      "     | > loss_mel_ce: 2.5950350761413574  (2.9925334053947856)\n",
      "     | > loss: 0.04092998802661896  (0.04712363657355302)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2476  (0.2453162896746681)\n",
      "     | > loader_time: 0.0082  (0.008748973619370253)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:24:10 -- STEP: 5300/6419 -- GLOBAL_STEP: 5300\u001b[0m\n",
      "     | > loss_text_ce: 0.022131482139229774  (0.02337907982006106)\n",
      "     | > loss_mel_ce: 2.977870225906372  (2.990936005430407)\n",
      "     | > loss: 0.04687502607703209  (0.047098673221496974)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2917  (0.24531389164474776)\n",
      "     | > loader_time: 0.0089  (0.008747442578369747)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:24:29 -- STEP: 5350/6419 -- GLOBAL_STEP: 5350\u001b[0m\n",
      "     | > loss_text_ce: 0.02655564807355404  (0.02338156190709531)\n",
      "     | > loss_mel_ce: 2.8480629920959473  (2.9895835718261914)\n",
      "     | > loss: 0.04491591453552246  (0.04707758022872636)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2908  (0.2452837024670895)\n",
      "     | > loader_time: 0.0085  (0.008745239248899694)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:24:48 -- STEP: 5400/6419 -- GLOBAL_STEP: 5400\u001b[0m\n",
      "     | > loss_text_ce: 0.02531464211642742  (0.02337834551206063)\n",
      "     | > loss_mel_ce: 2.9875741004943848  (2.988288170187566)\n",
      "     | > loss: 0.04707638546824455  (0.04705728931904384)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2506  (0.2452852084018566)\n",
      "     | > loader_time: 0.0084  (0.008744643396801458)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:25:07 -- STEP: 5450/6419 -- GLOBAL_STEP: 5450\u001b[0m\n",
      "     | > loss_text_ce: 0.02483799122273922  (0.023374960256073964)\n",
      "     | > loss_mel_ce: 3.0074591636657715  (2.986889536621377)\n",
      "     | > loss: 0.047379642724990845  (0.047035382775538495)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.1924  (0.2453371896218816)\n",
      "     | > loader_time: 0.0078  (0.00874235796272212)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:25:26 -- STEP: 5500/6419 -- GLOBAL_STEP: 5500\u001b[0m\n",
      "     | > loss_text_ce: 0.026762912049889565  (0.023370759464123002)\n",
      "     | > loss_mel_ce: 2.926621437072754  (2.985673005971045)\n",
      "     | > loss: 0.04614663124084473  (0.04701630884612142)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2497  (0.24529586579582907)\n",
      "     | > loader_time: 0.0083  (0.008737466421994333)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:25:45 -- STEP: 5550/6419 -- GLOBAL_STEP: 5550\u001b[0m\n",
      "     | > loss_text_ce: 0.023731904104351997  (0.02336746607412086)\n",
      "     | > loss_mel_ce: 2.83685564994812  (2.984073442811368)\n",
      "     | > loss: 0.04469668120145798  (0.04699126421197034)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2881  (0.24527417530884613)\n",
      "     | > loader_time: 0.008  (0.00873383483371223)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:26:04 -- STEP: 5600/6419 -- GLOBAL_STEP: 5600\u001b[0m\n",
      "     | > loss_text_ce: 0.025432860478758812  (0.02336722367675972)\n",
      "     | > loss_mel_ce: 2.7524025440216064  (2.982736251779968)\n",
      "     | > loss: 0.04340367764234543  (0.04697036681231105)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2686  (0.24533715835639408)\n",
      "     | > loader_time: 0.0084  (0.008733070407594993)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:26:23 -- STEP: 5650/6419 -- GLOBAL_STEP: 5650\u001b[0m\n",
      "     | > loss_text_ce: 0.02044767327606678  (0.023362021566887842)\n",
      "     | > loss_mel_ce: 2.864173412322998  (2.9813132455285705)\n",
      "     | > loss: 0.04507220536470413  (0.046948051057689955)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2473  (0.24532240006775982)\n",
      "     | > loader_time: 0.0086  (0.008732561263362956)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:26:42 -- STEP: 5700/6419 -- GLOBAL_STEP: 5700\u001b[0m\n",
      "     | > loss_text_ce: 0.0251455157995224  (0.023360504152808766)\n",
      "     | > loss_mel_ce: 2.809838056564331  (2.980166462638925)\n",
      "     | > loss: 0.044296618551015854  (0.04693010886640919)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2116  (0.2453087219857333)\n",
      "     | > loader_time: 0.0083  (0.00873103915599358)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:27:00 -- STEP: 5750/6419 -- GLOBAL_STEP: 5750\u001b[0m\n",
      "     | > loss_text_ce: 0.02527950517833233  (0.023355079541387734)\n",
      "     | > loss_mel_ce: 2.794689655303955  (2.978493791124098)\n",
      "     | > loss: 0.044062018394470215  (0.04690388861492918)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2501  (0.24527756127067235)\n",
      "     | > loader_time: 0.0091  (0.008732318670853357)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:27:19 -- STEP: 5800/6419 -- GLOBAL_STEP: 5800\u001b[0m\n",
      "     | > loss_text_ce: 0.02421409823000431  (0.02335411845128338)\n",
      "     | > loss_mel_ce: 2.7496345043182373  (2.9772486825647055)\n",
      "     | > loss: 0.04334138333797455  (0.04688441877542379)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2909  (0.24524914264678954)\n",
      "     | > loader_time: 0.009  (0.008733219483803085)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:27:38 -- STEP: 5850/6419 -- GLOBAL_STEP: 5850\u001b[0m\n",
      "     | > loss_text_ce: 0.02169082872569561  (0.023354461138319738)\n",
      "     | > loss_mel_ce: 3.0265417098999023  (2.9760000304686747)\n",
      "     | > loss: 0.04762863367795944  (0.04686491394272212)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2949  (0.24526603197440122)\n",
      "     | > loader_time: 0.0099  (0.008732472647968559)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:27:57 -- STEP: 5900/6419 -- GLOBAL_STEP: 5900\u001b[0m\n",
      "     | > loss_text_ce: 0.023260297253727913  (0.023359259785610712)\n",
      "     | > loss_mel_ce: 2.8579342365264893  (2.974606741565772)\n",
      "     | > loss: 0.04501866549253464  (0.04684321878446355)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2908  (0.24525731070566986)\n",
      "     | > loader_time: 0.0086  (0.008731761584847699)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:28:16 -- STEP: 5950/6419 -- GLOBAL_STEP: 5950\u001b[0m\n",
      "     | > loss_text_ce: 0.019436335191130638  (0.023353877381554644)\n",
      "     | > loss_mel_ce: 2.7537336349487305  (2.9732918931656553)\n",
      "     | > loss: 0.043330781161785126  (0.04682259017867696)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.1641  (0.2452793589359572)\n",
      "     | > loader_time: 0.0079  (0.00873200989570942)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:28:35 -- STEP: 6000/6419 -- GLOBAL_STEP: 6000\u001b[0m\n",
      "     | > loss_text_ce: 0.023358158767223358  (0.023346365494032673)\n",
      "     | > loss_mel_ce: 2.9600589275360107  (2.9719547402858764)\n",
      "     | > loss: 0.04661589115858078  (0.046801579790810684)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2149  (0.2453052099943161)\n",
      "     | > loader_time: 0.0099  (0.008731534719467198)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2025-07-17 11:28:54 -- STEP: 6050/6419 -- GLOBAL_STEP: 6050\u001b[0m\n",
      "     | > loss_text_ce: 0.02787262573838234  (0.02334475140649176)\n",
      "     | > loss_mel_ce: 3.0605828762054443  (2.9706894758713176)\n",
      "     | > loss: 0.048257116228342056  (0.0467817848144976)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.2863  (0.24534533268164013)\n",
      "     | > loader_time: 0.0095  (0.008732054765559456)\n",
      "\n",
      " > Keyboard interrupt detected.\n",
      " > Saving model before exiting...\n",
      "\n",
      " > CHECKPOINT : /kaggle/working/run/GPT_XTTS_v2.0_LJSpeech_FT-July-17-2025_10+49AM-0000000/checkpoint_6060.pth\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at inline_container.cc:603] . unexpected pos 5510800128 vs 5510800024",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1832\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1833\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1834\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/trainer/trainer.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1784\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip_train_epoch\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_with_eval\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1785\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1786\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_eval\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/trainer/trainer.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcur_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1504\u001b[0;31m             \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_num_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader_start_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1505\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/trainer/trainer.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, batch, batch_n_steps, step, loader_start_time)\u001b[0m\n\u001b[1;32m   1359\u001b[0m                 \u001b[0;31m# auto training with a single optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1360\u001b[0;31m                 outputs, loss_dict_new, step_time = self.optimize(\n\u001b[0m\u001b[1;32m   1361\u001b[0m                     \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/trainer/trainer.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, batch, model, optimizer, scaler, criterion, scheduler, config, optimizer_idx, step_optimizer, num_optimizers)\u001b[0m\n\u001b[1;32m   1281\u001b[0m                 \u001b[0;31m# main model optimizer step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1282\u001b[0;31m                 \u001b[0mloss_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1283\u001b[0m                 \u001b[0;31m# gradient accumulation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    849\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 850\u001b[0;31m             _save(\n\u001b[0m\u001b[1;32m    851\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m   1113\u001b[0m             \u001b[0;31m# Now that it is on the CPU we can directly copy it into the zip file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/fsspec/implementations/local.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_36/1667428889.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0meval_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m )\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1839\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" > Saving model before exiting...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1840\u001b[0m                 \u001b[0;31m# save the model on keyboard interrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1841\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1842\u001b[0m                 \u001b[0;31m# update the training dashboard logger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1843\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_training_dashboard_logger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/trainer/utils/distributed.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_main_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/trainer/trainer.py\u001b[0m in \u001b[0;36msave_checkpoint\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1935\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pick_target_avg_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeep_avg_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1937\u001b[0;31m         save_checkpoint(\n\u001b[0m\u001b[1;32m   1938\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1939\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/trainer/io.py\u001b[0m in \u001b[0;36msave_checkpoint\u001b[0;34m(config, model, optimizer, scaler, current_step, epoch, output_folder, save_n_checkpoints, save_func, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n > CHECKPOINT : %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m     save_model(\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/trainer/io.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(config, model, optimizer, scaler, current_step, epoch, output_path, save_func, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msave_func\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0msave_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0msave_fsspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/trainer/utils/distributed.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_main_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/trainer/logging/base_dash_logger.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(state, path)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mrank_zero_only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0msave_fsspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain_step_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/trainer/io.py\u001b[0m in \u001b[0;36msave_fsspec\u001b[0;34m(state, path, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \"\"\"\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfsspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 849\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    850\u001b[0m             _save(\n\u001b[1;32m    851\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_end_of_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    707\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:603] . unexpected pos 5510800128 vs 5510800024"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    TrainerArgs(\n",
    "        restore_path=None,\n",
    "        skip_train_epoch=False,\n",
    "        start_with_eval=START_WITH_EVAL,\n",
    "        grad_accum_steps=GRAD_ACUMM_STEPS,\n",
    "    ),\n",
    "    config,\n",
    "    output_path=OUT_PATH,\n",
    "    model=model,\n",
    "    train_samples=train_samples,\n",
    "    eval_samples=eval_samples,\n",
    ")\n",
    "trainer.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
